IDEAS for Domuns-client nearly-identical challenge
* Load at startup, in BACKRGOUND, DAEMOM, while app already up and running and allowing endpoint to be called
* Hmm, really, all-powerful stuff?
* ANYWAY - do we want to save in some REDIS db?
* ANYWAY - pages may be of VARYING SIZE, but TOTAL_NOF_PAGES is fixed
* If TOTAL_NOF_PAGES changes between calls, we send a SIGNAL to potentially still running LOAD_IT_ALL to stop_the_world_and_restart
* AND MORE NICETiES, like having an (optional) MAX_FETCH_TIME and, if exceeded, we return right now what we currently have (with ALSO_CONFIGURABLE return_status like INCOMPLETE, or OK)
*                                           YEP! If the [done] fetching somehow missed some pages, same INCOMPLETE result+status_code returned
* COOOOOOOOOOOOOOOOOOOOOOOOOL
* MAYBE MAYBE save the whole crap to SOME_DB  (SQLite?!!?!!) (all fields? for other possible endpoints usage? not sure!)
*   ** SOME_DB drawbacks
*   ** ===============
*   ** 1) HMMM, while fetching (at high speed) rows from EXTERNAL ENDPOINT, we'll need to save to SOME_DB
*   **    1.a) YEAH, that might slow things down
*   **    1.b) How could we prevent such slowdown? While still having IT ALL saved for "on next startup, all is quick"?
*   **    1.c) SPEEDING UP SAVING and RETRIEVAL to/from SOME_DB
*   **               1.c.1) Each FETCH ifself



XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
ORIGINAL CONTENT, circa 2024-Nov-12 or 13
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

  <!--
  TODO - keep removing obviously unused stuff
  TODO - do bare-bones implementation, my BEAN class for movies will only have DIRECtorNAME attrib... AND... we'll do max speed parallelization without fucking memmory...
  ...
  IDEA for not fucking memory...
     * Get page 1, see page size and nof pages
     * ASSUME that page size is homogeneous...
     * We want at most 1000 (VIRTuAL !!! ) threads at once, grabbing at most possibly 5000 movies into memory at once
     * CODE: multi-threading smart-ass that achieves this,
     *                * Let's say page-size is high, like 2000
     *                      * In that case, we can have AT MOST 2 (2 * 2k= 4k)     , 2   threads fetching data at once
     *                * In other case, page-size is low, like 20
     *                      * In that case, we can have AT MOST 250 (250 * 20= 5k) , 250 threads fetching data at once
  *                * You got the point. The "5000 max movies being read" can be calibrated do hundreds of thousands, maybe millions
                            *                                                                    (IMDB has, among movies, episodes, series, etc. 10+ million entries!!)
     *                *                    The maxVirtualThreads can also be calibrated to several thousand (like 100 thousand)
     *                * PLAN: be ready to deal with a change like "now, scan the whole IMDB".
     *=====================================================================================
     * The way data is returned so far seems IMPOSSIBLE TO CACHE, it is returned completely out of order and has no good PK candidate, thus, can change at any time
     *                I M P O R T A T : We are working with the "always has to call the API [maxPages] times EVERY SINGLE tIME MY DIReCTORS API IS CALLED< thus, SPEED FREAK WORRIES!
     * ANYWAY ... I believe that doing this speed-freak stuff will be enough to show off some skills. No unit tests, no nothing, FUCK OFF AND RUN!


     GRABBING IDEAS, PSEUDO-CODE
      * do a call to page 1, getting per_page, total_pages and total
        *** If 1st call has per_page == total, then IT'S OVER... do same per_thread processing with what we have and DONE
        *** ELSE...
          ** we'll already have done stuff to , like, Map<String, Integer> moviesByDirector
          ** So we're off to a good start possibly using threada
          ** Virtual Thread comes alive and dies lightly and quickly, we can be near careless about them
          ** TODO NOW - calculate max_threads
            ** DECISION: Will we keep spanning threads as they die, OR feed the threads with next-page-for-you ???
            ** THINKING... imagining 1000 pages (DECIDED EARLIER) to be gotten by 50 threads, no worries here on WHY it was decided
            **                   *** page always "page+1", because very 1st page gotten initially
            **
            **   thread 01 pg 01
            **   thread 02 pg 02
            **   thread 03 pg 03
            **      (...)           *** before all pages are gotten, threads 11 to 30 are done ___ LOGIC AA
            **   thread 50 pg 50
            **
            **
            **   LOGIC AA: how do I detect that threads 11 to 30 are done and, if necessary, start 20 (or less) new threads?
            **     ** Old-school wait/notify?
            **     ** Should I give each thread a "public void run()" like...
            **        public void run() {
            **           // HERE WE GO! A decent RUN() implementarion for a thread pool
            **           while ((int myPage = someStructure.threadSafeTakeOwnershipOfPage()) != -1) {
            **               // -1 means "ouch, it seems thre's no page for you, we're close to done,
            **               // maybe other threads already doint all remaining pages"
            **               doStuffHttpClientBlaBlaGET_and_MAP_PUT_oneMore_to_directorsFound();
            **           }
            **        }
// rbattaglia - good example of thread pool with virtual threads, from MEDIUM.COM
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class VirtualThreadPool {

    public static void main(String[] args) {

        ExecutorService executor = Executors.newVirtualThreadExecutor();

        for (int i = 0; i < 10; i++) {
            executor.submit(() -> {
                // rbattaglia - core of our "public void run()" above
                System.out.println("Running task in a virtual thread: "
                                   + Thread.currentThread().getName());
            });
        }
        executor.shutdown();
        // rbattaglia - here, we have (ConcurrentHash?)Map<String, Integer> moviesByDirector all ok, populated;
        return SOMETHING_LIKE moviesByDirector.entrySet().stream()
             .filter(es->es.getValue() > thresholdFromOurURL)
             .map(es->es.getKey()
             .sorted().toList();
        // WOW, that can be our endpoint output, or ALMOST that, COOOOOL !!! ;
        // Nevermind 404 or crap like that, we're SPEED FREAKS, not endpoint bureaucrats
    }
}
